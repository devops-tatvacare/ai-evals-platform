# LLM Evaluation System - Implementation Plan

## Overview

Implement a two-call LLM evaluation system with:
1. **Call 1 (Transcription)**: Audio â†’ AI Transcript
2. **Call 2 (Critique)**: Audio + Original + AI Transcript â†’ Per-segment critique

Template variables (`{{audio}}`, `{{transcript}}`, etc.) with availability checking.

---

## Phase 1: Structure & Foundation

### 1.1 Type Definitions

**File: `src/types/eval.types.ts`** (extend existing)

```typescript
// Add these types

export interface SegmentCritique {
  segmentIndex: number;
  originalText: string;
  llmText: string;
  critique: string;
  severity: 'none' | 'minor' | 'moderate' | 'critical';
  category?: string; // e.g., 'dosage', 'speaker', 'medical-term'
}

export interface EvaluationCritique {
  segments: SegmentCritique[];
  overallAssessment: string;
  generatedAt: Date;
  model: string;
}

// Update AIEvaluation interface
export interface AIEvaluation {
  id: string;
  createdAt: Date;
  model: string;
  status: EvalStatus;
  // Call 1 result
  llmTranscript?: TranscriptData;
  // Call 2 result (NEW)
  critique?: EvaluationCritique;
  // Programmatic comparison
  comparison?: TranscriptComparison;
  error?: string;
  // Track which call failed
  failedAt?: 'transcription' | 'critique';
}
```

**File: `src/types/template.types.ts`** (NEW)

```typescript
export type TemplateVariableType = 'text' | 'file' | 'computed';

export interface TemplateVariable {
  key: string;           // e.g., '{{audio}}'
  type: TemplateVariableType;
  description: string;
  availableIn: ('transcription' | 'evaluation' | 'extraction')[];
}

export interface TemplateVariableStatus {
  key: string;
  available: boolean;
  reason?: string;       // Why unavailable
  value?: string | Blob; // Resolved value if available
}

export interface PromptValidationResult {
  isValid: boolean;
  variables: TemplateVariableStatus[];
  missingRequired: string[];
  unknownVariables: string[];
}
```

---

### 1.2 Template Variable System

**File: `src/services/templates/variableRegistry.ts`** (NEW)

```typescript
// Central registry of all template variables
export const TEMPLATE_VARIABLES: Record<string, TemplateVariable> = {
  '{{audio}}': {
    key: '{{audio}}',
    type: 'file',
    description: 'Audio file for transcription/evaluation',
    availableIn: ['transcription', 'evaluation'],
  },
  '{{transcript}}': {
    key: '{{transcript}}',
    type: 'text',
    description: 'Original transcript text',
    availableIn: ['evaluation', 'extraction'],
  },
  '{{llm_transcript}}': {
    key: '{{llm_transcript}}',
    type: 'computed',
    description: 'AI-generated transcript (from Call 1)',
    availableIn: ['evaluation'],
  },
  // Extensible: add more variables here
};

export function getAvailableVariables(promptType: string): TemplateVariable[];
export function validatePrompt(prompt: string, context: VariableContext): PromptValidationResult;
export function resolveVariables(prompt: string, context: VariableContext): ResolvedPrompt;
```

**File: `src/services/templates/variableResolver.ts`** (NEW)

```typescript
// Resolves variables from listing/evaluation context
export interface VariableContext {
  listing: Listing;
  aiEval?: AIEvaluation;
  audioBlob?: Blob;
}

export function resolveVariable(
  key: string, 
  context: VariableContext
): TemplateVariableStatus;

export function resolveAllVariables(
  prompt: string,
  context: VariableContext
): Map<string, TemplateVariableStatus>;
```

**File: `src/services/templates/index.ts`** (NEW)

```typescript
export * from './variableRegistry';
export * from './variableResolver';
```

---

### 1.3 Settings Schema Update

**File: `src/features/settings/schema/settingsSchema.ts`** (modify)

```typescript
// Add evaluationPrompt to LLM settings
llm: {
  apiKey: string;
  selectedModel: string;
  transcriptionPrompt: string;  // existing
  evaluationPrompt: string;     // NEW - for Call 2
  extractionPrompt: string;     // existing
}
```

**Default Evaluation Prompt:**
```
You are evaluating a medical transcription for accuracy.

ORIGINAL TRANSCRIPT:
{{transcript}}

AI-GENERATED TRANSCRIPT:
{{llm_transcript}}

AUDIO REFERENCE: {{audio}}

For each segment, compare the original with the AI-generated version.
Provide a JSON response with:
{
  "segments": [
    {
      "segmentIndex": 0,
      "critique": "Description of any differences or issues",
      "severity": "none|minor|moderate|critical",
      "category": "optional category like 'dosage', 'speaker-id', 'medical-term'"
    }
  ],
  "overallAssessment": "Summary of transcription quality"
}
```

---

### 1.4 Evaluation Service Refactor

**File: `src/services/llm/evaluationService.ts`** (NEW - extract from hook)

```typescript
export interface TranscriptionResult {
  transcript: TranscriptData;
  rawResponse: string;
}

export interface CritiqueResult {
  critique: EvaluationCritique;
  rawResponse: string;
}

export interface EvaluationProgress {
  stage: 'preparing' | 'transcribing' | 'critiquing' | 'comparing' | 'complete' | 'failed';
  message: string;
  callNumber?: 1 | 2;
}

export class EvaluationService {
  // Call 1: Transcription
  async transcribe(
    audioBlob: Blob,
    mimeType: string,
    prompt: string,
    onProgress: (progress: EvaluationProgress) => void
  ): Promise<TranscriptionResult>;

  // Call 2: Critique
  async critique(
    context: {
      audioBlob: Blob;
      mimeType: string;
      originalTranscript: TranscriptData;
      llmTranscript: TranscriptData;
    },
    prompt: string,
    onProgress: (progress: EvaluationProgress) => void
  ): Promise<CritiqueResult>;

  // Full evaluation (both calls + metrics)
  async evaluate(
    listing: Listing,
    prompts: { transcription: string; evaluation: string },
    onProgress: (progress: EvaluationProgress) => void
  ): Promise<AIEvaluation>;
}
```

---

### 1.5 State Management Updates

**File: `src/stores/taskQueueStore.ts`** (modify)

```typescript
// Update task type to track call number
export interface LLMTask {
  // ... existing fields
  callNumber?: 1 | 2;  // NEW: which call in evaluation flow
  stage?: string;      // NEW: current stage
}
```

---

### 1.6 Debug Panel Integration

**File: `src/services/logger/evaluationLogger.ts`** (NEW)

```typescript
// Specialized logging for evaluation flow
export function logEvaluationStart(listingId: string, prompts: { transcription: string; evaluation: string });
export function logCall1Start(listingId: string);
export function logCall1Complete(listingId: string, segmentCount: number);
export function logCall1Failed(listingId: string, error: string);
export function logCall2Start(listingId: string);
export function logCall2Complete(listingId: string, critiqueCount: number);
export function logCall2Failed(listingId: string, error: string);
export function logEvaluationComplete(listingId: string, metrics: { wer: number; cer: number });
```

---

### Phase 1 Checklist

- [ ] 1.1 Add type definitions (`SegmentCritique`, `EvaluationCritique`, update `AIEvaluation`)
- [ ] 1.2 Create template types (`TemplateVariable`, `TemplateVariableStatus`, etc.)
- [ ] 1.3 Create `src/services/templates/` folder with registry and resolver
- [ ] 1.4 Update settings schema with `evaluationPrompt`
- [ ] 1.5 Update settings store with default evaluation prompt
- [ ] 1.6 Create `EvaluationService` class (extract from hook)
- [ ] 1.7 Update task queue store for call tracking
- [ ] 1.8 Create evaluation logger utilities
- [ ] 1.9 Build and test types compile correctly

---

## Phase 2: Implementation & UI

### 2.1 Settings UI Update

**File: `src/features/settings/components/SettingsPage.tsx`** (modify)

Add Evaluation Prompt section in Prompts tab:
- Textarea for evaluation prompt
- Show available variables: `{{audio}}`, `{{transcript}}`, `{{llm_transcript}}`
- Variable chip/badge UI showing which are available

**File: `src/features/settings/components/VariableChips.tsx`** (NEW)

```typescript
// Reusable component showing available variables for a prompt type
interface VariableChipsProps {
  promptType: 'transcription' | 'evaluation' | 'extraction';
  onInsert?: (variable: string) => void;
}
```

---

### 2.2 Evaluation Modal

**File: `src/features/evals/components/EvaluationModal.tsx`** (NEW)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Evaluation                                               [X]     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚ Step 1: Transcription Prompt                      [Reset to Default]â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ [editable textarea with prompt]                                 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ Variables: âœ“ {{audio}}                                              â”‚
â”‚                                                                     â”‚
â”‚ Step 2: Evaluation Prompt                         [Reset to Default]â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ [editable textarea with prompt]                                 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ Variables: âœ“ {{audio}}  âœ“ {{transcript}}  â³ {{llm_transcript}}     â”‚
â”‚                                                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ âš ï¸ {{unknown_var}} is not a recognized variable                 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                     â”‚
â”‚                                         [Cancel]  [Run Evaluation]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Features:
- Load defaults from settings
- Validate variables in real-time
- Show variable availability status
- Disable "Run" if required variables missing

---

### 2.3 Update AIEvalRequest Component

**File: `src/features/evals/components/AIEvalRequest.tsx`** (modify)

- "Request AI Evaluation" â†’ Opens `EvaluationModal`
- "Rerun Evaluation" â†’ Opens `EvaluationModal` (same)
- Show progress with call indication: "Call 1/2: Transcribing..." or "Call 2/2: Critiquing..."

---

### 2.4 Update useAIEvaluation Hook

**File: `src/features/evals/hooks/useAIEvaluation.ts`** (modify)

```typescript
export function useAIEvaluation() {
  // Update to use EvaluationService
  // Accept prompts parameter
  // Track call number in progress
  
  const evaluate = async (
    listing: Listing,
    prompts: { transcription: string; evaluation: string }
  ) => {
    // Call 1
    setProgress('Call 1/2: Transcribing audio...');
    logger.info('Starting Call 1: Transcription', { listingId: listing.id });
    const transcriptionResult = await service.transcribe(...);
    
    // Call 2
    setProgress('Call 2/2: Generating critique...');
    logger.info('Starting Call 2: Critique', { listingId: listing.id });
    const critiqueResult = await service.critique(...);
    
    // Compute metrics
    setProgress('Computing metrics...');
    const metrics = computeAllMetrics(...);
    
    // Save
    ...
  };
}
```

---

### 2.5 Update Human Review UI

**File: `src/features/evals/components/HumanEvalNotepad.tsx`** (modify)

Update `SegmentRow` component to show:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ORIGINAL       â”‚         AI GENERATED            â”‚  HUMAN CORRECTION  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Speaker badge]    â”‚ [Speaker badge]                 â”‚                    â”‚
â”‚ "Original text"    â”‚ "AI generated text"             â”‚ Click to correct   â”‚
â”‚                    â”‚                                 â”‚                    â”‚
â”‚                    â”‚ â”Œâ”€ Critique â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                    â”‚
â”‚                    â”‚ â”‚ ğŸ’¬ LLM analysis of segment  â”‚ â”‚                    â”‚
â”‚                    â”‚ â”‚ Severity: [badge]           â”‚ â”‚                    â”‚
â”‚                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                    â”‚
â”‚                    â”‚                                 â”‚                    â”‚
â”‚                    â”‚ â”Œâ”€ Metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                    â”‚
â”‚                    â”‚ â”‚ ED: 3 | 89% [Good]          â”‚ â”‚                    â”‚
â”‚                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**File: `src/features/evals/components/SegmentCritiqueCard.tsx`** (NEW)

```typescript
interface SegmentCritiqueCardProps {
  critique: SegmentCritique;
}
// Displays the LLM critique with severity badge and category
```

---

### 2.6 Debug Panel Updates

**File: `src/features/debug/components/DebugPanel.tsx`** (modify)

Tasks tab should show:
- Task type: `ai_eval`
- Stage indicator: `Call 1/2` or `Call 2/2`
- Clear call progression in task details

Logs tab should capture:
- Evaluation start with prompts used
- Call 1 start/complete/fail
- Call 2 start/complete/fail
- Metrics computed
- Full flow completion

---

### 2.7 Progress Indicator Enhancement

**File: `src/features/evals/components/EvaluationProgress.tsx`** (NEW)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Evaluation in Progress                                              â”‚
â”‚                                                                     â”‚
â”‚  â—â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â—‹â”€â”€â”€â”€â”€â”€â”€â”€â—‹                                       â”‚
â”‚  Prepare  Call 1   Call 2   Done                                    â”‚
â”‚           â–²                                                         â”‚
â”‚           â””â”€ Transcribing audio... (42%)                            â”‚
â”‚                                                                     â”‚
â”‚                                                    [Cancel]         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Phase 2 Checklist

- [ ] 2.1 Update SettingsPage with evaluation prompt textarea
- [ ] 2.2 Create `VariableChips` component for variable display/insertion
- [ ] 2.3 Create `EvaluationModal` component
- [ ] 2.4 Update `AIEvalRequest` to open modal
- [ ] 2.5 Refactor `useAIEvaluation` hook for two-call flow
- [ ] 2.6 Create `SegmentCritiqueCard` component
- [ ] 2.7 Update `HumanEvalNotepad` to show critique + metrics per segment
- [ ] 2.8 Create `EvaluationProgress` component with call stages
- [ ] 2.9 Update Debug Panel for call tracking
- [ ] 2.10 Add evaluation logging throughout flow
- [ ] 2.11 Test full flow: Modal â†’ Call 1 â†’ Call 2 â†’ Display in Human Review
- [ ] 2.12 Test error states: missing variables, API failures, partial failures
- [ ] 2.13 Test rerun functionality

---

## Dependencies Graph

```
Phase 1 (Foundation)
â”œâ”€â”€ 1.1 Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”œâ”€â”€ 1.2 Template Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                               â–¼
â”œâ”€â”€ 1.3 Template Service â—„â”€â”€â”€â”€â”€â”€â”¤
â”‚       â”‚                       â”‚
â”‚       â–¼                       â”‚
â”œâ”€â”€ 1.4 Settings Schema â—„â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       â”‚                       â”‚
â”‚       â–¼                       â”‚
â”œâ”€â”€ 1.5 Settings Store â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                               â”‚
â”œâ”€â”€ 1.6 EvaluationService â—„â”€â”€â”€â”€â”€â”¤
â”‚       â”‚                       â”‚
â”‚       â–¼                       â”‚
â”œâ”€â”€ 1.7 Task Queue Store â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                               â”‚
â””â”€â”€ 1.8 Evaluation Logger â”€â”€â”€â”€â”€â”€â”˜

Phase 2 (Implementation)
â”œâ”€â”€ 2.1 Settings UI â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1.4, 1.5
â”‚       â”‚
â”œâ”€â”€ 2.2 VariableChips â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1.3
â”‚       â”‚
â”œâ”€â”€ 2.3 EvaluationModal â—„â”€â”€â”€â”€â”€â”€â”€ 2.1, 2.2, Phase 1.3
â”‚       â”‚
â”œâ”€â”€ 2.4 AIEvalRequest â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2.3
â”‚       â”‚
â”œâ”€â”€ 2.5 useAIEvaluation â—„â”€â”€â”€â”€â”€â”€â”€ Phase 1.6, 1.7, 1.8
â”‚       â”‚
â”œâ”€â”€ 2.6 SegmentCritiqueCard â—„â”€â”€â”€ Phase 1.1
â”‚       â”‚
â”œâ”€â”€ 2.7 HumanEvalNotepad â—„â”€â”€â”€â”€â”€â”€ 2.6, existing EditDistanceBadge
â”‚       â”‚
â”œâ”€â”€ 2.8 EvaluationProgress â—„â”€â”€â”€â”€ Phase 1.6
â”‚       â”‚
â””â”€â”€ 2.9 Debug Panel â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Phase 1.7, 1.8
```

---

## Data Flow

```
User clicks "Request AI Evaluation"
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EvaluationModal       â”‚
â”‚   - Load prompts        â”‚
â”‚   - Validate variables  â”‚
â”‚   - User edits/confirms â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ [Run Evaluation]
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   useAIEvaluation       â”‚â”€â”€â”€â”€â”€â”€â–¶ Logger: "Evaluation started"
â”‚   - Resolve variables   â”‚â”€â”€â”€â”€â”€â”€â–¶ TaskQueue: Add task (stage: preparing)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CALL 1: Transcribe    â”‚â”€â”€â”€â”€â”€â”€â–¶ Logger: "Call 1 started"
â”‚   - Send audio + prompt â”‚â”€â”€â”€â”€â”€â”€â–¶ TaskQueue: Update (stage: transcribing, call: 1)
â”‚   - Parse response      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ Success
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CALL 2: Critique      â”‚â”€â”€â”€â”€â”€â”€â–¶ Logger: "Call 2 started"
â”‚   - Send all context    â”‚â”€â”€â”€â”€â”€â”€â–¶ TaskQueue: Update (stage: critiquing, call: 2)
â”‚   - Parse critique      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ Success
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Compute Metrics       â”‚â”€â”€â”€â”€â”€â”€â–¶ Logger: "Metrics computed"
â”‚   - WER, CER, Match     â”‚
â”‚   - Per-segment ED      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Save to Listing       â”‚â”€â”€â”€â”€â”€â”€â–¶ Logger: "Evaluation complete"
â”‚   - llmTranscript       â”‚â”€â”€â”€â”€â”€â”€â–¶ TaskQueue: Complete task
â”‚   - critique            â”‚
â”‚   - comparison          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UI Updates            â”‚
â”‚   - MetricsBar          â”‚
â”‚   - HumanEvalNotepad    â”‚
â”‚   - EvalsView           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Error Handling

| Error Point | Handling |
|-------------|----------|
| Missing {{audio}} | Modal shows error, disable Run button |
| Missing {{transcript}} | Modal shows warning (for eval prompt) |
| Unknown variable | Modal shows warning, allow proceed |
| Call 1 API failure | Save partial state, show error, allow retry |
| Call 1 parse failure | Log raw response, show error with details |
| Call 2 API failure | Keep Call 1 result, show error, allow retry Call 2 only |
| Call 2 parse failure | Keep Call 1 result, log raw response |
| Network offline | Show offline warning before starting |

---

## Files Summary

### Phase 1 - New Files
- `src/types/template.types.ts`
- `src/services/templates/variableRegistry.ts`
- `src/services/templates/variableResolver.ts`
- `src/services/templates/index.ts`
- `src/services/llm/evaluationService.ts`
- `src/services/logger/evaluationLogger.ts`

### Phase 1 - Modified Files
- `src/types/eval.types.ts`
- `src/features/settings/schema/settingsSchema.ts`
- `src/stores/settingsStore.ts`
- `src/stores/taskQueueStore.ts`

### Phase 2 - New Files
- `src/features/settings/components/VariableChips.tsx`
- `src/features/evals/components/EvaluationModal.tsx`
- `src/features/evals/components/SegmentCritiqueCard.tsx`
- `src/features/evals/components/EvaluationProgress.tsx`

### Phase 2 - Modified Files
- `src/features/settings/components/SettingsPage.tsx`
- `src/features/evals/components/AIEvalRequest.tsx`
- `src/features/evals/hooks/useAIEvaluation.ts`
- `src/features/evals/components/HumanEvalNotepad.tsx`
- `src/features/debug/components/DebugPanel.tsx`
